{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script OPN - Files consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary libraries\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape df_faults_lte_1: (1801, 12), file: 1\n",
      "shape df_gsm_1: (2865, 36), file: 1\n",
      "shape df_wcdma_1: (11365, 54), file: 1\n",
      "shape df_faults_lte_total: (3602, 12), file: 2\n",
      "shape df_gsm_total: (5730, 36), file: 1\n",
      "shape df_wbts_1: (2712, 11), file: 1\n",
      "shape df_faults_lte_total: (5403, 12), file: 3\n",
      "shape df_lte_1: (15232, 36), file: 1\n",
      "shape df_faults_lte_total: (7204, 12), file: 4\n",
      "shape df_wcdma_total: (22730, 54), file: 2\n",
      "shape df_lte_total: (30464, 36), file: 2\n",
      "shape df_wbts_total: (5424, 11), file: 2\n",
      "shape df_faults_lte_total: (9005, 12), file: 5\n"
     ]
    }
   ],
   "source": [
    "# ruta base de la ubicación de los files\n",
    "path = \"/home/opm/Documentos-opm/OPN_COLOMBIA/ANALISYS/input_files\"\n",
    "\n",
    "# Lista con el nombre de todos los archivos excel\n",
    "xlsx_files_list = glob.glob( path + \"/*.xlsx\" )\n",
    "\n",
    "# identifiers by technology\n",
    "faults_lte = \"Fallas_TX_LTE\"\n",
    "gsm_monitoring = \"GSM_NPO_Monitoring_v4\"\n",
    "lte_monitoring = \"LTE_FL16A_NPO_Monitoring_V4\"\n",
    "wbts_monitoring = \"WBTS_WCDMA17_NPO_MONITORING\"\n",
    "wcdma_monitoring = \"WCDMA17_NPO_Monitoring_V4\"\n",
    "\n",
    "# Revisar cada archivo excel según tecnologia\n",
    "\n",
    "# initialize counters\n",
    "faults_lte_count = 0\n",
    "gsm_monitoring_count = 0\n",
    "lte_monitoring_count = 0\n",
    "wbts_monitoring_count = 0\n",
    "wcdma_monitoring_count = 0\n",
    "\n",
    "# file identification by technology\n",
    "for xlsx_file in range( len( xlsx_files_list ) ):\n",
    "    \n",
    "    # file search\n",
    "    if faults_lte in xlsx_files_list[ xlsx_file ]:\n",
    "                \n",
    "        # read file\n",
    "        if faults_lte_count < 1:\n",
    "            \n",
    "            faults_lte_count += 1\n",
    "            \n",
    "            df_faults_lte_1 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "            \n",
    "            df_faults_lte_1 = df_faults_lte_1.drop( labels=0, axis=0 )\n",
    "            # validation print\n",
    "            print( f'shape df_faults_lte_1: {df_faults_lte_1.shape}, file: {faults_lte_count}' )\n",
    "            #print( f'Fault LTE file: {faults_lte_count}' )\n",
    "        else:\n",
    "            df_faults_lte_2 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "            \n",
    "            faults_lte_count += 1\n",
    "            \n",
    "            df_faults_lte_2 = df_faults_lte_2.drop( labels=0, axis=0 )\n",
    "            \n",
    "            df_faults_lte_total = pd.concat( [ df_faults_lte_1, df_faults_lte_2 ], ignore_index=True )\n",
    "            \n",
    "            df_faults_lte_1 = df_faults_lte_total.copy()\n",
    "            # validation print    \n",
    "            #print( f'shape df_faults_lte_total: {df_lte_total.shape}' )\n",
    "            print( f'shape df_faults_lte_total: {df_faults_lte_total.shape}, file: {faults_lte_count}' )\n",
    "            #print( f'Fault LTE file: {faults_lte_count}' )\n",
    "        \n",
    "        \n",
    "    ## search GSM monitoring***\n",
    "    elif gsm_monitoring in xlsx_files_list[ xlsx_file ]:\n",
    "        \n",
    "        # read file\n",
    "        if gsm_monitoring_count < 1:\n",
    "            \n",
    "            gsm_monitoring_count += 1\n",
    "            \n",
    "            df_gsm_1 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "            \n",
    "            df_gsm_1 = df_gsm_1.drop( labels=0, axis=0 )\n",
    "            # validation print\n",
    "            print( f'shape df_gsm_1: {df_gsm_1.shape}, file: {gsm_monitoring_count}' )\n",
    "            #print( f'GSM files: {gsm_monitoring_count}' )\n",
    "            \n",
    "        else:\n",
    "            df_gsm_2 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "            \n",
    "            df_gsm_2 = df_gsm_2.drop( labels=0, axis=0 )\n",
    "            \n",
    "            df_gsm_total = pd.concat( [ df_gsm_1, df_gsm_2 ], ignore_index=True )\n",
    "            \n",
    "            df_gsm_1 = df_gsm_total.copy()\n",
    "            # validation print    \n",
    "            print( f'shape df_gsm_total: {df_gsm_total.shape}, file: {gsm_monitoring_count}' )\n",
    "            #print( f'GSM file: {gsm_monitoring_count}' )\n",
    "                \n",
    "            \n",
    "    ## search LTE monitoring \n",
    "    elif lte_monitoring in xlsx_files_list[ xlsx_file ]:\n",
    "        \n",
    "        # read file\n",
    "        if lte_monitoring_count < 1:\n",
    "            \n",
    "            lte_monitoring_count += 1\n",
    "            \n",
    "            df_lte_1 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "            \n",
    "            df_lte_1 = df_lte_1.drop( labels=0, axis=0 )\n",
    "            # validation print\n",
    "            print( f'shape df_lte_1: {df_lte_1.shape}, file: {lte_monitoring_count}' )\n",
    "            #print( f'LTE file: {lte_monitoring_count}' )\n",
    "            \n",
    "        else:\n",
    "            df_lte_2 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "            \n",
    "            lte_monitoring_count += 1\n",
    "            \n",
    "            df_lte_2 = df_lte_2.drop( labels=0, axis=0 )\n",
    "            \n",
    "            df_lte_total = pd.concat( [ df_lte_1, df_lte_2 ], ignore_index=True )\n",
    "            \n",
    "            df_lte_1 = df_lte_total.copy()\n",
    "            # validation print    \n",
    "            print( f'shape df_lte_total: {df_lte_total.shape}, file: {lte_monitoring_count}' )\n",
    "            #print( f'LTE file: {lte_monitoring_count}' )\n",
    "        \n",
    "                \n",
    "    ## search WBTS monitoring\n",
    "    elif wbts_monitoring in xlsx_files_list[ xlsx_file ]:\n",
    "        \n",
    "        # read file\n",
    "        if wbts_monitoring_count < 1:\n",
    "            \n",
    "            wbts_monitoring_count += 1\n",
    "            \n",
    "            df_wbts_1 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "            \n",
    "            df_wbts_1 = df_wbts_1.drop( labels=0, axis=0 )\n",
    "            # validation print\n",
    "            print( f'shape df_wbts_1: {df_wbts_1.shape}, file: {wbts_monitoring_count}' )\n",
    "            #print( f'WBTS file: {wbts_monitoring_count}' )\n",
    "            \n",
    "        else:\n",
    "            df_wbts_2 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "            \n",
    "            wbts_monitoring_count += 1\n",
    "            \n",
    "            df_wbts_2 = df_wbts_2.drop( labels=0, axis=0 )\n",
    "            \n",
    "            df_wbts_total = pd.concat( [ df_wbts_1, df_wbts_2 ], ignore_index=True )\n",
    "            \n",
    "            df_wbts_1 = df_wbts_total.copy()\n",
    "            # validation print    \n",
    "            print( f'shape df_wbts_total: {df_wbts_total.shape}, file: {wbts_monitoring_count}' )\n",
    "            #print( f'WBTS file: {wbts_monitoring_count}' )\n",
    "\n",
    "        \n",
    "    ## search WCDMA monitoring\n",
    "    elif wcdma_monitoring in xlsx_files_list[ xlsx_file ]:\n",
    "        \n",
    "        # read file\n",
    "        if wcdma_monitoring_count < 1:\n",
    "            \n",
    "            wcdma_monitoring_count += 1\n",
    "            \n",
    "            df_wcdma_1 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "            \n",
    "            df_wcdma_1 = df_wcdma_1.drop( labels=0, axis=0 )\n",
    "            # validation print\n",
    "            print( f'shape df_wcdma_1: {df_wcdma_1.shape}, file: {wcdma_monitoring_count}' )\n",
    "            #print( f'WBTS file: {wbts_monitoring_count}' )\n",
    "            \n",
    "        else:\n",
    "            df_wcdma_2 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "            \n",
    "            wcdma_monitoring_count += 1\n",
    "            \n",
    "            df_wcdma_2 = df_wcdma_2.drop( labels=0, axis=0 )\n",
    "            \n",
    "            df_wcdma_total = pd.concat( [ df_wcdma_1, df_wcdma_2 ], ignore_index=True )\n",
    "            \n",
    "            df_wcdma_1 = df_wcdma_total.copy()\n",
    "            # validation print    \n",
    "            print( f'shape df_wcdma_total: {df_wcdma_total.shape}, file: {wcdma_monitoring_count}' )\n",
    "            #print( f'WBTS file: {wbts_monitoring_count}' )\n",
    "\n",
    "    \n",
    "    ## No valid files\n",
    "    else:\n",
    "        #print( \"No valid files\" )\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atributos para eliminar valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **  Faults LTE filter **\n",
    "# A: 'Period start time'\n",
    "# C: 'LNBTS name'\n",
    "# F: 'ATT_INTER_ENB_HO (M8014C6)'\n",
    "columns_faults_lte = df_faults_lte_total.columns.to_list()\n",
    "\n",
    "#print( 'Faults LTE:',columns_faults_lte )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **  GSM filter **\n",
    "# A: 'Period start time'\n",
    "# B: 'BSC name'\n",
    "# D: 'BTS name'\n",
    "\n",
    "columns_gsm_monitoring = df_gsm_total.columns.to_list()\n",
    "#print( 'GSM Monitoring:',columns_gsm_monitoring )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **  LTE monitoring filter **\n",
    "# A: 'Period start time'\n",
    "# D: 'LNCEL name'\n",
    "\n",
    "columns_lte_monitoring = df_lte_total.columns.to_list()\n",
    "#print( 'LTE Monitoring:',columns_lte_monitoring )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **  WBTS monitoring filter **\n",
    "# A: 'Period start time'\n",
    "# D: 'WBTS name'\n",
    "# E: 'WBTS ID'\n",
    "columns_wbts_monitoring = df_wbts_total.columns.to_list()\n",
    "#print( 'WBTS Monitoring:',columns_wbts_monitoring )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** WCDMA monitoring filter **\n",
    "# A: 'Period start time'\n",
    "# F: 'WCEL name'\n",
    "# G: 'WCEL ID'\n",
    "columns_wcdma_monitoring = df_wcdma_total.columns.to_list()\n",
    "#print( 'WCDMA Monitoring:',columns_wcdma_monitoring )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos para eliminar valores duplicados\n",
    "faults_lte_duplicate = [ 'Period start time', 'LNBTS name', 'ATT_INTER_ENB_HO (M8014C6)' ]\n",
    "gsm_monitoring_duplicate = [ 'Period start time', 'BSC name', 'BTS name' ]\n",
    "lte_monitoring_duplicate = [ 'Period start time', 'LNCEL name' ]\n",
    "wbts_monitoring_duplicate = [ 'Period start time', 'WBTS name', 'WBTS ID' ]\n",
    "wcdma_monitoring_duplicate = [ 'Period start time', 'WCEL name', 'WCEL ID' ]\n",
    "\n",
    "\n",
    "# El orden de las tecnologías coincide en ambos archivos\n",
    "duplicate_list = [ faults_lte_duplicate, gsm_monitoring_duplicate, lte_monitoring_duplicate, \n",
    "                  wbts_monitoring_duplicate, wcdma_monitoring_duplicate]\n",
    "\n",
    "df_total_list = [ df_faults_lte_total, df_gsm_total, df_lte_total, df_wbts_total, df_wcdma_total ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removiendo valores duplicados en las columnas indicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before delete duplicate FAULT LTE: (9005, 12)\n",
      "shape after delete duplicate FAULT LTE: (1801, 12)\n",
      "shape before delete duplicate GSM: (5730, 36)\n",
      "shape after delete duplicate GSM: (2865, 36)\n",
      "shape before delete duplicate LTE: (30464, 36)\n",
      "shape after delete duplicate LTE: (15016, 36)\n",
      "shape before delete duplicate WBTS: (5424, 11)\n",
      "shape after delete duplicate WBTS: (2712, 11)\n",
      "shape before delete duplicate WCDMA: (22730, 54)\n",
      "shape after delete duplicate WCDMA: (11361, 54)\n"
     ]
    }
   ],
   "source": [
    "# Removiendo valores duplicados\n",
    "\n",
    "print( f'shape before delete duplicate FAULT LTE: {df_faults_lte_total.shape}' )\n",
    "\n",
    "# Eliminar duplicados en faults lte\n",
    "df_faults_lte_unique = df_faults_lte_total.drop_duplicates( \n",
    "                                                             subset=faults_lte_duplicate,\n",
    "                                                             ignore_index=True \n",
    "                                                             )\n",
    "\n",
    "print( f'shape after delete duplicate FAULT LTE: {df_faults_lte_unique.shape}' )\n",
    "\n",
    "# Eliminar duplicados en gsm total\n",
    "print( f'shape before delete duplicate GSM: {df_gsm_total.shape}' )\n",
    "df_gsm_unique = df_gsm_total.drop_duplicates( \n",
    "                                               subset=gsm_monitoring_duplicate,\n",
    "                                                             ignore_index=True \n",
    "                                                             )\n",
    "\n",
    "print( f'shape after delete duplicate GSM: {df_gsm_unique.shape}' )\n",
    "\n",
    "# Eliminar duplicados en LTE total\n",
    "print( f'shape before delete duplicate LTE: {df_lte_total.shape}' )\n",
    "df_lte_unique = df_lte_total.drop_duplicates( \n",
    "                                               subset=lte_monitoring_duplicate,\n",
    "                                                        ignore_index=True \n",
    "                                                              )\n",
    "\n",
    "print( f'shape after delete duplicate LTE: {df_lte_unique.shape}' )\n",
    "\n",
    "# Eliminar duplicados en WBTS total [pendind]\n",
    "print( f'shape before delete duplicate WBTS: {df_wbts_total.shape}' )\n",
    "df_wbts_unique = df_wbts_total.drop_duplicates( \n",
    "                                               subset=wbts_monitoring_duplicate,\n",
    "                                                        ignore_index=True \n",
    "                                                              )\n",
    "\n",
    "print( f'shape after delete duplicate WBTS: {df_wbts_unique.shape}' )\n",
    "\n",
    "# Eliminar duplicados en WCDMA total [pendind]\n",
    "print( f'shape before delete duplicate WCDMA: {df_wcdma_total.shape}' )\n",
    "df_wcdma_unique = df_wcdma_total.drop_duplicates( \n",
    "                                               subset=wcdma_monitoring_duplicate,\n",
    "                                                        ignore_index=True \n",
    "                                                              )\n",
    "\n",
    "print( f'shape after delete duplicate WCDMA: {df_wcdma_unique.shape}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pendiente:\n",
    "# Realizar una abstracción de mayor nivel, para lograr una función. Probar con un bucle anidado.\n",
    "\n",
    "# for df in range( len( df_total_list ) ):\n",
    "#     #print(f'Shape df_{df}: {df_total_list[df].shape}')\n",
    "    \n",
    "#     for duplicate in range( len( duplicate_list ) ):\n",
    "        \n",
    "#         df_without_duplicate = df_total_list[df].drop_duplicates( \n",
    "#                                                                 subset=[ duplicate_list[duplicate] ],\n",
    "#                                                                 ignore_index=True \n",
    "#                                                                 )\n",
    "\n",
    "#         print( f'shape after delete duplicate: {df_without_duplicate.shape}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtro por sitios únicos por tecnología"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de archivos consolidados sin duplicados\n",
    "files_list_unique = [\n",
    "                    df_faults_lte_unique, df_gsm_unique, df_lte_unique, \n",
    "                    df_wbts_unique, df_wcdma_unique\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_faults_lte_unique.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para normalizar el nombre de los sitios por \n",
    "# archivo por tecnología\n",
    "\n",
    "def norm_name(site:str) -> str:\n",
    "    \"\"\"normaliza los nombres de los sitios, \n",
    "    colocando los nombres en minúscula y sustituyendo los caracteres\n",
    "    '.', ':', ' ' y '-' por '_'\n",
    "\n",
    "    Args:\n",
    "        site (str): nombre del sitio original\n",
    "\n",
    "    Returns:\n",
    "        site (str): nombre del sitio normalizado    \n",
    "    \"\"\"\n",
    "    \n",
    "    site = site.lower()\n",
    "    signs = [' ', '.', ':', '-']\n",
    "    for c in range( len( site ) ):\n",
    "        if site[c] in signs:\n",
    "            site = site.replace(site[c] , '_')\n",
    "        \n",
    "    return site\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7041/2786337442.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_faults_lte_unique[ faults_lte_filter ] = df_faults_lte_unique[ faults_lte_filter ].apply( norm_name );\n",
      "/tmp/ipykernel_7041/2786337442.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_gsm_unique[ gsm_filter ] = df_gsm_unique[ gsm_filter ].apply( norm_name );\n",
      "/tmp/ipykernel_7041/2786337442.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_lte_unique[ lte_filter ] = df_lte_unique[ lte_filter ].apply( norm_name );\n",
      "/tmp/ipykernel_7041/2786337442.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_wbts_unique[ wbts_filter ] = df_wbts_unique[ wbts_filter ].apply( norm_name );\n",
      "/tmp/ipykernel_7041/2786337442.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_wcdma_unique[ wcdma_filter ] = df_wcdma_unique[ wcdma_filter ].apply( norm_name );\n"
     ]
    }
   ],
   "source": [
    "# Normalización de los nombres de los sitios\n",
    "\n",
    "faults_lte_filter = 'LNBTS name'\n",
    "gsm_filter = 'BCF name'\n",
    "lte_filter = 'LNBTS name'\n",
    "wbts_filter = 'WBTS name'\n",
    "wcdma_filter = 'WBTS name'\n",
    "\n",
    " \n",
    "df_faults_lte_unique[ faults_lte_filter ] = df_faults_lte_unique[ faults_lte_filter ].apply( norm_name );\n",
    "df_gsm_unique[ gsm_filter ] = df_gsm_unique[ gsm_filter ].apply( norm_name );\n",
    "df_lte_unique[ lte_filter ] = df_lte_unique[ lte_filter ].apply( norm_name );\n",
    "df_wbts_unique[ wbts_filter ] = df_wbts_unique[ wbts_filter ].apply( norm_name );\n",
    "df_wcdma_unique[ wcdma_filter ] = df_wcdma_unique[ wcdma_filter ].apply( norm_name );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_faults_lte_unique.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro por sitio según tecnología\n",
    "\n",
    "# Faults ---> LNBTS NAME\n",
    "# GSM-- > BCF NAME\n",
    "# LTE -- > LNBTS Name\n",
    "# WBTS---> WBTS NAME\n",
    "# WCDMA ----> WBTS NAME\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lista de atributos a filtrar por archivo\n",
    "attribute_filter_list = [\n",
    "                    faults_lte_filter, gsm_filter, lte_filter, \n",
    "                    wbts_filter, wcdma_filter\n",
    "                    ]\n",
    "\n",
    "# posible lista de prefijos para los df\n",
    "# att_filter_list_names = [ \n",
    "#                         'faults_lte_sites', 'gsm_sites', 'lte_sites', \n",
    "#                         'wbts_sites', 'wcdma_sites'\n",
    "#                          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de los sitios únicos por atributo por archivo\n",
    "#print( f'fualts LTE' )\n",
    "fault_lte_sites = list(df_faults_lte_unique[faults_lte_filter].unique())\n",
    "#print( f'Len: { len( fault_lte_sites ) }' )\n",
    "#print( fault_lte_sites )\n",
    "\n",
    "#print( 'GSM:' )\n",
    "gsm_sites = list( df_gsm_unique[gsm_filter].unique() )\n",
    "#print( f'Len: { len( gsm_sites ) }' )\n",
    "#print( gsm_sites )\n",
    "\n",
    "#print( 'LTE:' )\n",
    "lte_sites = list( df_lte_unique[lte_filter].unique() )\n",
    "#print( f'Len: { len( lte_sites ) }' )\n",
    "#print( len(lte_sites) )\n",
    "\n",
    "#print( 'WBTS:' )\n",
    "wbts_sites = list( df_wbts_unique[wbts_filter].unique() )\n",
    "#print( f'Len: { len( wbts_sites ) }' )\n",
    "#print( wbts_sites )\n",
    "\n",
    "#print( 'WCDMA:' )\n",
    "wcdma_sites = list( df_wcdma_unique[wcdma_filter].unique() )\n",
    "#print( f'Len: { len( wcdma_sites ) }' )\n",
    "#print( wcdma_sites )\n",
    "\n",
    "# No puede ser un diccionario, porque no se puede determinar el número de sitios\n",
    "# que se encontraran por por \n",
    "\n",
    "unique_sites = [\n",
    "    fault_lte_sites, gsm_sites, lte_sites, \n",
    "    wbts_sites, wcdma_sites\n",
    "]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guarda en un diccionario la clave: nombre del df y valor el df correspondiente\n",
    "# Filtrado por los nombres de los sitios de cada archivo\n",
    "\n",
    "# Dic Faults LTE\n",
    "d_f_lte = {}\n",
    "for item in fault_lte_sites:\n",
    "    d_f_lte[item] = df_faults_lte_unique[ \n",
    "                      df_faults_lte_unique[ faults_lte_filter ] ==  item \n",
    "                                  ]\n",
    "    #print( f'df_{item}: {d_f_lte[item].shape}' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_bog_cc_titan_2: (573, 36)\n",
      "df_bog_puente_grande: (573, 36)\n",
      "df_bog_periodistas_1: (573, 36)\n",
      "df_bog_la_esmeralda_2: (573, 36)\n",
      "df_bog_atavanza: (573, 36)\n"
     ]
    }
   ],
   "source": [
    "# Dic GSM\n",
    "d_gsm = {}\n",
    "for item in gsm_sites:\n",
    "    d_gsm[item] = df_gsm_unique[ \n",
    "                      df_gsm_unique[ gsm_filter ] ==  item \n",
    "                                ]\n",
    "    print( f'df_{item}: {d_gsm[item].shape}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_bca_terminal: (1614, 36)\n",
      "df_bog_atavanza: (2674, 36)\n",
      "df_bog_cc_titan_2: (3282, 36)\n",
      "df_bog_la_esmeralda_2: (1434, 36)\n",
      "df_bog_periodistas_1: (1678, 36)\n",
      "df_bog_puente_grande: (3053, 36)\n",
      "df_bog_recodo_del_country_h1: (1281, 36)\n"
     ]
    }
   ],
   "source": [
    "# Dic LTE\n",
    "d_lte = {}\n",
    "for item in lte_sites:\n",
    "    d_lte[item] = df_lte_unique[ \n",
    "                      df_lte_unique[ lte_filter ] ==  item \n",
    "                                ]\n",
    "    print( f'df_{item}: {d_lte[item].shape}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_bog_atavanza: (574, 11)\n",
      "df_bog_recodo_del_country_h1: (355, 11)\n",
      "df_bog_la_esmeralda_2: (376, 11)\n",
      "df_bog_puente_grande: (540, 11)\n",
      "df_bog_cc_titan_2: (494, 11)\n",
      "df_bog_periodistas_1: (373, 11)\n"
     ]
    }
   ],
   "source": [
    "# Dic WBTS\n",
    "d_wbts = {}\n",
    "for item in wbts_sites:\n",
    "    d_wbts[item] = df_wbts_unique[ \n",
    "                      df_wbts_unique[ wbts_filter ] ==  item \n",
    "                                ]\n",
    "    print( f'df_{item}: {d_wbts[item].shape}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_bog_atavanza: (2292, 54)\n",
      "df_bog_puente_grande: (2292, 54)\n",
      "df_bog_recodo_del_country_h1: (1337, 54)\n",
      "df_bog_cc_titan_2: (2194, 54)\n",
      "df_bog_periodistas_1: (1527, 54)\n",
      "df_bog_la_esmeralda_2: (1719, 54)\n"
     ]
    }
   ],
   "source": [
    "# Dic WCDMA\n",
    "d_wcdma = {}\n",
    "for item in wcdma_sites:\n",
    "    d_wcdma[item] = df_wcdma_unique[ \n",
    "                      df_wcdma_unique[ wcdma_filter ] ==  item \n",
    "                                ]\n",
    "    print( f'df_{item}: {d_wcdma[item].shape}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta los archivos FAULTS LTE\n",
    "from pathlib import Path\n",
    "\n",
    "for key, value in d_f_lte.items():\n",
    "    file_path = Path( f'output_files/f_lte_{key}.csv' )\n",
    "    file_path.parent.mkdir( parents=True, exist_ok=True )\n",
    "    #print(f'{key}: {value.shape}')\n",
    "    value.to_csv(file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta los archivos GSM\n",
    "for key, value in d_gsm.items():\n",
    "    file_path = Path( f'output_files/gsm_{key}.csv' )\n",
    "    file_path.parent.mkdir( parents=True, exist_ok=True )\n",
    "    #print(f'{key}: {value.shape}')\n",
    "    value.to_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta los archivos LTE\n",
    "for key, value in d_lte.items():\n",
    "    file_path = Path( f'output_files/lte_{key}.csv' )\n",
    "    file_path.parent.mkdir( parents=True, exist_ok=True )\n",
    "    #print(f'{key}: {value.shape}')\n",
    "    value.to_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta los archivos WBTS\n",
    "for key, value in d_wbts.items():\n",
    "    file_path = Path( f'output_files/wbts_{key}.csv' )\n",
    "    file_path.parent.mkdir( parents=True, exist_ok=True )\n",
    "    #print(f'{key}: {value.shape}')\n",
    "    value.to_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta los archivos WCDMA\n",
    "for key, value in d_wcdma.items():\n",
    "    file_path = Path( f'output_files/wcdma_{key}.csv' )\n",
    "    file_path.parent.mkdir( parents=True, exist_ok=True )\n",
    "    #print(f'{key}: {value.shape}')\n",
    "    value.to_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo del filtro de un sitio para \n",
    "# #df_faults_lte_unique[ \n",
    "#                      df_faults_lte_unique[ faults_lte_filter ] == 'BCA.Terminal' \n",
    "#                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar los sitio únicos por archivo\n",
    "\n",
    "# for site in fault_lte_sites:\n",
    "#     #print( fault_lte_sites[ site ] )\n",
    "#     # df_faults_lte_filtered[ df_faults_lte_filtered[ faults_lte_filter ] == 'BCA.Terminal' ]\n",
    "#     print( f'Site: df_faul_lte_{site}:' )\n",
    "#     df_faul_lte_site = \n",
    "    \n",
    "    #display( df_faults_lte_filtered[ df_faults_lte_filtered[ faults_lte_filter ] == fault_lte_sites[site] ])\n",
    "    # df_faults_lte_filtered[ df_faults_lte_filtered[ faults_lte_filter ] == fault_lte_sites[site] ]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition\n",
    "\n",
    "def file_consolidation( file_tech: str ) -> dict:\n",
    "    \"\"\"consolidates in a single df the data by technology\n",
    "\n",
    "    Args:\n",
    "        file_tech (str): file prefix by technology\n",
    "\n",
    "    Returns:\n",
    "        Dict: DataFrame with data consolidated by technology\n",
    "    \"\"\"\n",
    "    \n",
    "    # necessary libraries\n",
    "    import pandas as pd\n",
    "    import glob\n",
    "    \n",
    "    # folder path with the data\n",
    "    path = \"/home/opm/Documentos-opm/OPN_COLOMBIA/ANALISYS/input_files\"\n",
    "    \n",
    "    # global variable\n",
    "    global df_total\n",
    "\n",
    "    # List of file names\n",
    "    xlsx_files_list = glob.glob( path + \"/*.xlsx\" )\n",
    "    \n",
    "    # initialize counter\n",
    "    file_count = 0\n",
    "\n",
    "    # file identification by technology\n",
    "    for xlsx_file in range( len( xlsx_files_list ) ):\n",
    "        \n",
    "        # file search\n",
    "        if file_tech in xlsx_files_list[ xlsx_file ]:\n",
    "                    \n",
    "            # read file\n",
    "            if file_count < 1:\n",
    "                \n",
    "                file_count += 1\n",
    "                \n",
    "                df_1 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "                \n",
    "                df_1 = df_1.drop( labels=0, axis=0 )\n",
    "                # validation print\n",
    "                #print( f'shape df_1: {df_1.shape}' )\n",
    "            else:\n",
    "                df_2 = pd.read_excel( io=xlsx_files_list[ xlsx_file ] )\n",
    "                \n",
    "                file_count += 1\n",
    "                \n",
    "                df_2 = df_2.drop( labels=0, axis=0 )\n",
    "                \n",
    "                df_total = pd.concat( [ df_1, df_2 ], ignore_index=True )\n",
    "                \n",
    "                df_1 = df_total.copy()\n",
    "        \n",
    "    # Dictionary of results\n",
    "    results = {\n",
    "        'TECHNOLOGY':file_tech, \n",
    "        'df_total SHAPE': df_total.shape, \n",
    "        'TOTAL FILES': file_count\n",
    "    }\n",
    "    #print( f'shape {file_tech}: {df_total.shape}' )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TECHNOLOGY': 'Fallas_TX_LTE', 'df_total SHAPE': (9005, 12), 'TOTAL FILES': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_consolidation(\"Fallas_TX_LTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period start time</th>\n",
       "      <th>MRBTS name</th>\n",
       "      <th>LNBTS name</th>\n",
       "      <th>E-UTRAN HP att, inter eNB S1</th>\n",
       "      <th>SCTP S1 succ trans R</th>\n",
       "      <th>ATT_INTER_ENB_HO (M8014C6)</th>\n",
       "      <th>X2 stp att</th>\n",
       "      <th>SCTP X2 succ trans R</th>\n",
       "      <th>Inter eNB E-UTRAN tot HO SR X2</th>\n",
       "      <th>TWAMP tx SR</th>\n",
       "      <th>avgRTT_15Min</th>\n",
       "      <th>maxRTT_15Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-01 09:00:00</td>\n",
       "      <td>BCA.Terminal</td>\n",
       "      <td>BCA.Terminal</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2698</td>\n",
       "      <td>0</td>\n",
       "      <td>99.97558</td>\n",
       "      <td>99.184883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-01 10:00:00</td>\n",
       "      <td>BCA.Terminal</td>\n",
       "      <td>BCA.Terminal</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3025</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>98.77686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-01 11:00:00</td>\n",
       "      <td>BCA.Terminal</td>\n",
       "      <td>BCA.Terminal</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>3631</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>98.623348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Period start time    MRBTS name    LNBTS name  \\\n",
       "0 2022-05-01 09:00:00  BCA.Terminal  BCA.Terminal   \n",
       "1 2022-05-01 10:00:00  BCA.Terminal  BCA.Terminal   \n",
       "2 2022-05-01 11:00:00  BCA.Terminal  BCA.Terminal   \n",
       "\n",
       "  E-UTRAN HP att, inter eNB S1 SCTP S1 succ trans R  \\\n",
       "0                            0                  100   \n",
       "1                            0                  100   \n",
       "2                            9                  100   \n",
       "\n",
       "  ATT_INTER_ENB_HO (M8014C6) X2 stp att SCTP X2 succ trans R  \\\n",
       "0                       2698          0             99.97558   \n",
       "1                       3025          0                  100   \n",
       "2                       3631          2                  100   \n",
       "\n",
       "  Inter eNB E-UTRAN tot HO SR X2 TWAMP tx SR avgRTT_15Min maxRTT_15Min  \n",
       "0                      99.184883         NaN          NaN          NaN  \n",
       "1                       98.77686         NaN          NaN          NaN  \n",
       "2                      98.623348         NaN          NaN          NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TECHNOLOGY': 'Fallas_TX_LTE', 'df_total SHAPE': (9005, 12), 'TOTAL FILES': 5}\n",
      "{'TECHNOLOGY': 'GSM_NPO_Monitoring_v4', 'df_total SHAPE': (5730, 36), 'TOTAL FILES': 2}\n",
      "{'TECHNOLOGY': 'LTE_FL16A_NPO_Monitoring_V4', 'df_total SHAPE': (30464, 36), 'TOTAL FILES': 2}\n",
      "{'TECHNOLOGY': 'WBTS_WCDMA17_NPO_MONITORING', 'df_total SHAPE': (5424, 11), 'TOTAL FILES': 2}\n",
      "{'TECHNOLOGY': 'WCDMA17_NPO_Monitoring_V4', 'df_total SHAPE': (22730, 54), 'TOTAL FILES': 2}\n"
     ]
    }
   ],
   "source": [
    "# tests\n",
    "files_tech_id = [\n",
    "    \"Fallas_TX_LTE\",\n",
    "    \"GSM_NPO_Monitoring_v4\", \n",
    "    \"LTE_FL16A_NPO_Monitoring_V4\", \n",
    "    \"WBTS_WCDMA17_NPO_MONITORING\", \n",
    "    \"WCDMA17_NPO_Monitoring_V4\"\n",
    "    ]\n",
    "\n",
    "for file in range( len( files_tech_id ) ):\n",
    "    \n",
    "    print( file_consolidation( files_tech_id[ file ] ))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3313d7862e35f23cb796a0d5e1a05f5386948db6518b51457360428deb8d3fb3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
